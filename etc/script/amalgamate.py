#!/usr/bin/env python3
# coding=utf-8

# amalgamate.py - Amalgamate C source and header files.
# Copyright (c) 2012, Erik Edlund <erik.edlund@32767.se>
#
# Redistribution and use in source and binary forms, with or without modification,
# are permitted provided that the following conditions are met:
#
#  * Redistributions of source code must retain the above copyright notice,
#  this list of conditions and the following disclaimer.
#
#  * Redistributions in binary form must reproduce the above copyright notice,
#  this list of conditions and the following disclaimer in the documentation
#  and/or other materials provided with the distribution.
#
#  * Neither the name of Erik Edlund, nor the names of its contributors may
#  be used to endorse or promote products derived from this software without
#  specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
# ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
# ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

import argparse
import datetime
import json
import os
import re

class Amalgamation(object):

    # Prepends self.source_path to file_path if needed.
    def actual_path(self, file_path):
        if not os.path.isabs(file_path):
            file_path = os.path.join(self.source_path, file_path)
        return file_path

    # Search included file_path in self.include_paths and
    # in source_dir if specified.
    def find_included_file(self, file_path, source_dir):
        search_dirs = self.include_paths[:]
        if source_dir:
            search_dirs.insert(0, source_dir)

        for search_dir in search_dirs:
            search_path = os.path.join(search_dir, file_path)
            if os.path.isfile(self.actual_path(search_path)):
                return search_path
        return None

    def __init__(self, args):
        with open(args.config, 'r') as f:
            config = json.loads(f.read())
            for key in config:
                setattr(self, key, config[key])

            self.verbose = args.verbose == "yes"
            self.prologue = args.prologue
            self.source_path = args.source_path
            self.included_files = []

    # Generate the amalgamation and write it to the target file.
    def generate(self):
        amalgamation = ""

        if self.prologue:
            with open(self.prologue, 'r') as f:
                amalgamation += datetime.datetime.now().strftime(f.read())

        if self.verbose:
            print("Config:")
            print(" target        = {0}".format(self.target))
            print(" working_dir   = {0}".format(os.getcwd()))
            print(" include_paths = {0}".format(self.include_paths))
        print("Creating amalgamation:")
        for file_path in self.sources:
            # Do not check the include paths while processing the source
            # list, all given source paths must be correct.
            # actual_path = self.actual_path(file_path)
            print(" - processing \"{0}\"".format(file_path))
            t = TranslationUnit(file_path, self, True)
            amalgamation += t.content

        # name of guard
        guard_name = re.sub(r'\W', '_', self.target.upper())
        guard_name = f'_AMALGAMATE_GUARD__{guard_name}_'
        # Add guard protection
        begin = '// Generated by amalgamate.py\n'
        begin += f'#ifndef {guard_name}\n'
        begin += f'#define {guard_name}\n'
        end = f'\n#endif // #ifndef {guard_name}'

        with open(self.target, 'w') as f:
            f.write(begin + amalgamation + end)

        print("...done!\n")
        if self.verbose:
            print("Files processed: {0}".format(self.sources))
            print("Files included: {0}".format(self.included_files))
        print("")


def _is_within(match, matches):
    for m in matches:
        if match.start() > m.start() and \
                match.end() < m.end():
            return True
    return False


class TranslationUnit(object):
    # // C++ comment.
    cpp_comment_pattern = re.compile(r"//.*?\n")

    # /* C comment. */
    c_comment_pattern = re.compile(r"/\*.*?\*/", re.S)

    # "complex \"stri\\\ng\" value".
    string_pattern = re.compile("[^']" r'".*?(?<=[^\\])"', re.S)

    # Handle simple include directives. Support for advanced
    # directives where macros and defines needs to expanded is
    # not a concern right now.
    include_pattern = re.compile(
        r'#\s*include\s+(<|")(?P<path>.*?)("|>)', re.S)

    # #pragma once
    pragma_once_pattern = re.compile(r'#\s*pragma\s+once', re.S)

    # Search for pattern in self.content, add the match to
    # contexts if found and update the index accordingly.
    def _search_content(self, index, pattern, contexts):
        match = pattern.search(self.content, index)
        if match:
            contexts.append(match)
            return match.end()
        return index + 2

    # Return all the skippable contexts, i.e., comments and strings
    def _find_skippable_contexts(self):
        # Find contexts in the content in which a found include
        # directive should not be processed.
        skippable_contexts = []

        # Walk through the content char by char, and try to grab
        # skippable contexts using regular expressions when found.
        i = 1
        content_len = len(self.content)
        while i < content_len:
            j = i - 1
            current = self.content[i]
            previous = self.content[j]

            if current == '"':
                # String value.
                i = self._search_content(j, self.string_pattern,
                                         skippable_contexts)
            elif current == '*' and previous == '/':
                # C style comment.
                i = self._search_content(j, self.c_comment_pattern,
                                         skippable_contexts)
            elif current == '/' and previous == '/':
                # C++ style comment.
                i = self._search_content(j, self.cpp_comment_pattern,
                                         skippable_contexts)
            else:
                # Skip to the next char.
                i += 1

        return skippable_contexts

    # Returns True if the match is within list of other matches

    # Removes pragma once from content
    def _process_pragma_once(self):
        content_len = len(self.content)
        if content_len < len("#include <x>"):
            return 0

        # Find contexts in the content in which a found include
        # directive should not be processed.
        skippable_contexts = self._find_skippable_contexts()

        pragmas = []
        pragma_once_match = self.pragma_once_pattern.search(self.content)
        while pragma_once_match:
            if not _is_within(pragma_once_match, skippable_contexts):
                pragmas.append(pragma_once_match)

            pragma_once_match = self.pragma_once_pattern.search(self.content,
                                                                pragma_once_match.end())

        # Handle all collected pragma once directives.
        prev_end = 0
        tmp_content = ''
        for pragma_match in pragmas:
            tmp_content += self.content[prev_end:pragma_match.start()]
            prev_end = pragma_match.end()
        tmp_content += self.content[prev_end:]
        self.content = tmp_content

    # Include all trivial #include directives into self.content.
    def _process_includes(self):
        content_len = len(self.content)
        if content_len < len("#include <x>"):
            return 0

        # Find contexts in the content in which a found include
        # directive should not be processed.
        skippable_contexts = self._find_skippable_contexts()

        # Search for include directives in the content, collect those
        # which should be included into the content.
        includes = []
        include_match = self.include_pattern.search(self.content)
        while include_match:
            if not _is_within(include_match, skippable_contexts):
                include_path = include_match.group("path")
                search_same_dir = include_match.group(1) == '"'
                found_included_path = self.amalgamation.find_included_file(
                    include_path, self.file_dir if search_same_dir else None)
                if found_included_path:
                    includes.append((include_match, found_included_path))

            include_match = self.include_pattern.search(self.content,
                                                        include_match.end())

        # Handle all collected include directives.
        prev_end = 0
        tmp_content = ''
        has_write_include = False
        for include in includes:
            include_match, found_included_path = include
            tmp_content += self.content[prev_end:include_match.start()]
            tmp_content += "// {0}".format(include_match.group(0))
            if found_included_path not in self.amalgamation.included_files:
                has_write_include = True
                t = TranslationUnit(found_included_path, self.amalgamation, False)
                tmp_content += t.content
            else:
                tmp_content += " (already included)"
            prev_end = include_match.end()
        if len(includes) > 0:
            tmp_content += '\n'
        if has_write_include:
            tmp_content += f"\n// {'-' * (len(self.file_path) + 8)}\n// Content {self.file_path}\n// {'-' * (len(self.file_path) + 8)}\n"
        while self.content[prev_end] == '\n':
            prev_end += 1
        tmp_content += '\n'
        tmp_content += self.content[prev_end:]
        tmp_content += '\n'

        self.content = tmp_content

        return len(includes)

    # add inline at begin of function or method
    def _process_inline(self):
        def replace_comments_and_strings(text):
            def replace_by_space(matchobj):
                return ' ' * len(matchobj.group(0))
            text = re.sub(r"\\\\(?<!$)", replace_by_space, text, flags=re.MULTILINE)
            text = re.sub(r'"(?s).*?(?:(?<!\\)")|\'(?s).*?(?:(?<!\\)\')|\/\*(?s).*?\*\/|\/\/(?s).*?(?:(?<!\\)$)', replace_by_space, text, flags=re.MULTILINE)
            text = re.sub(r"#(?s).*?(?:(?<!\\)$)", replace_by_space, text, flags=re.MULTILINE)
            text = list(text)
            for search in re.finditer(r"(\b__[a-z_A-Z]+(?:__)?|\bthrow|\bnoexcept|\balignas|(?:->\s*)?\bdecltype)\s*[(]", str(text), flags=re.MULTILINE):
                level = 0
                for i in range(*search.span(0)):
                    if text[i] == '{' or text[i] == '}':
                        text[i] = ' ' # delete in parenthesis
                    if text[i] == '(':
                        text[i] = ' ' # delete in parenthesis
                        level+=1
                    elif text[i] == ')':
                        text[i] = ' ' # delete in parenthesis
                        level-=1
                        if level == 0:
                            isPrototype = False
                            for j in range(i + 1, len(text)):
                                if text[j] == ' ' or text[j] == '\t' or text[j] == '\r' or text[j] == '\n':
                                    continue
                                elif text[j] == ';':
                                    isPrototype = True
                                    break
                                else:
                                    break
                            if isPrototype == False:
                                text[search.span(1)[1]] = ':'
                            break
            text = ''.join(text)
            text = re.sub(r"(?:\bthrow\b|\bnoexcept\b|\balignas\b|(?:->\s*)?\bdecltype\b|\bstruct\b|\bstatic\b|\bunion\b|\benum\b|\bconst\b|\bsizeof\b|\boverride\b|\bvolatile\b)", replace_by_space, text, flags=re.MULTILINE)
            return text

        def get_parenthesis_index(text, index):
            startParenthesis = -1
            endParenthesis = -1
            for i in range(index, len(text)):
                if '(' == text[i]:
                    startParenthesis = i + 1
                    break
            if startParenthesis < 0:
                return None

            level = 1
            for i in range(startParenthesis, len(text)):
                if text[i] == ':' and i + 1 < len(text) and text[i+1] == ':':
                    i+=1
                elif level == 1 and text[i] == ')':
                    endParenthesis = i
                    level-=1
                    i+=1
                    while re.match(r"\s", text[i], flags=re.MULTILINE):
                        i+=1
                    if text[i] == '-' and text[i + 1] == '>':
                        i+=2
                        while re.match(r"\s", text[i], flags=re.MULTILINE):
                            i+=1
                        while re.match(r";|{|:|=", text[i], flags=re.MULTILINE) is None:
                            i+=1
                    if text[i] == '=' and text[i + 1] != '=':
                        i+=1
                        while re.match(r"\s", text[i], flags=re.MULTILINE):
                            i+=1
                        while re.match(r";|{|:", text[i], flags=re.MULTILINE) is None:
                            i+=1
                    if text[i] == ':' or text[i] == '{' or text[i] == ';':
                        return [startParenthesis, endParenthesis, i]
                    else:
                        i-=1
                elif level > 0 and text[i] == ')':
                    level-=1
                elif level == 0 and text[i] == '(':
                    startParenthesis = i + 1
                    level = 1
                elif text[i] == '(':
                    level+=1

            return None

        def get_open_brace_index(text, index):
            for i in range(index, len(text)):
                if text[i] == '(' or text[i] == ';':
                    return None
                if text[i] == ':' or text[i] == '{':
                    return i
            return None

        def get_close_brace_index(text, index, isConstructor):
            level = 0 - 1 if isConstructor else 0
            for i in range(index, len(text)):
                if level < 0 and text[i] == ';':
                    return i
                elif level == 0 and text[i] == '}':
                    if isConstructor:
                        save = i
                        i+=1
                        while re.match(r"\s", text[i], flags=re.MULTILINE):
                            i+=1
                        if text[i] != ',' and text[i] != '{':
                            return save
                        level-=1
                        i-=1
                    else:
                        return i
                elif level > 0 and text[i] == '}':
                    level-=1
                elif text[i] == '{':
                    level+=1
            return None

        def search_function(text:str):
            new_inline_index = []
            endParenthesis = 0
            parenthesis = get_parenthesis_index(text, endParenthesis)
            while parenthesis:
                endParenthesis = parenthesis[2]
                startBrace = get_open_brace_index(text, endParenthesis)
                if startBrace == None:
                    parenthesis = get_parenthesis_index(text, endParenthesis)
                    pass
                    # no inline on front of prototype
                else:
                    isConstructor = text[startBrace] == ":"
                    startBrace+=1
                    endBrace = get_close_brace_index(text, startBrace, isConstructor)
                    if endBrace == None:
                        parenthesis = get_parenthesis_index(text, endParenthesis)
                        continue
                    # add inline on front line
                    while re.match(r"$", text[parenthesis[0]], flags=re.MULTILINE) is None:
                        parenthesis[0]-=1
                    while re.match(r"\s", text[parenthesis[0]], flags=re.MULTILINE):
                        parenthesis[0]+=1
                    if re.match(r".*\binline\b.*", text[parenthesis[0]:parenthesis[1]]) is None:
                        new_inline_index.append(parenthesis[0])
                    # words = searchPrototypes(parenthesis[0], parenthesis[1])
                    endParenthesis = endBrace
                parenthesis = get_parenthesis_index(text, endParenthesis)
            return new_inline_index

        tmp_content = self.content
        transform_content = replace_comments_and_strings(tmp_content)
        new_inline_index = search_function(transform_content)
        index = 0
        for inline_index in new_inline_index:
            tmp_content = tmp_content[:inline_index + index] + 'inline ' + tmp_content[inline_index + index:]
            index += len('inline ')

        self.content = tmp_content

    # Make all content processing
    def _process(self):
        if not self.is_root:
            self._process_pragma_once()
        self._process_includes()
        self._process_inline()
        self.content = f"\n// {'-' * (len(self.file_path) + 6)}\n// Start {self.file_path}\n// {'-' * (len(self.file_path) + 6)}\n" + self.content + f"\n// {'-' * (len(self.file_path) + 4)}\n// End {self.file_path}\n// {'-' * (len(self.file_path) + 4)}\n"

    def __init__(self, file_path, amalgamation, is_root):
        self.file_path = file_path
        self.file_dir = os.path.dirname(file_path)
        self.amalgamation = amalgamation
        self.is_root = is_root

        self.amalgamation.included_files.append(self.file_path)

        actual_path = self.amalgamation.actual_path(file_path)
        if not os.path.isfile(actual_path):
            raise IOError("File not found: \"{0}\"".format(file_path))
        with open(actual_path, 'r') as f:
            self.content = f.read()
            self._process()


def main():
    description = "Amalgamate C source and header files."
    usage = " ".join([
        "amalgamate.py",
        "[-v]",
        "-c path/to/config.json",
        "-s path/to/source/dir",
        "[-p path/to/prologue.(c|h)]"
    ])
    argsparser = argparse.ArgumentParser(
        description=description, usage=usage)

    argsparser.add_argument("-v", "--verbose", dest="verbose",
                            choices=["yes", "no"], metavar="", help="be verbose")

    argsparser.add_argument("-c", "--config", dest="config",
                            required=True, metavar="", help="path to a JSON config file")

    argsparser.add_argument("-s", "--source", dest="source_path",
                            required=True, metavar="", help="source code path")

    argsparser.add_argument("-p", "--prologue", dest="prologue",
                            required=False, metavar="", help="path to a C prologue file")

    amalgamation = Amalgamation(argsparser.parse_args())
    amalgamation.generate()


if __name__ == "__main__":
    main()
